# Diversifier Configuration Template

[logging]
level = "INFO"
console = true
file_path = "diversifier.log"
max_file_size = 10485760  # 10MB
backup_count = 5
enable_correlation_ids = true

[mcp]
filesystem_server_path = "src/mcp_servers/filesystem/server.py"
testing_server_path = "src/mcp_servers/testing/server.py"
git_server_path = "src/mcp_servers/git/server.py"
docker_server_path = "src/mcp_servers/docker/server.py"
timeout = 30
retry_attempts = 3

[migration]
max_iterations = 5
test_timeout = 300
backup_original = true
validate_syntax = true
require_test_coverage = true
min_test_coverage = 0.8

[performance]
enable_metrics = true
metrics_file = "performance_metrics.json"
log_slow_operations = true
slow_operation_threshold = 1.0
enable_memory_tracking = false

[llm]
# LLM Provider: Use correct LangChain provider names  
# See https://python.langchain.com/docs/integrations/chat/ for all supported providers
provider = "anthropic"
model_name = "claude-3-5-sonnet-20241022"
api_key_env_var = "ANTHROPIC_API_KEY"  # REQUIRED: Environment variable name for API key
temperature = 0.1  # Default temperature for all tasks
max_tokens = 4096
timeout = 120
retry_attempts = 3
# Optional: Custom API endpoint URL
# base_url = "https://api.anthropic.com"

# Task-specific temperatures (override default temperature for specific tasks)
[llm.task_temperatures]
analyzer = 0.1  # Lower for precise analysis
migrator = 0.2  # Slightly higher for code transformation
tester = 0.3  # Higher for creative test generation
repairer = 0.2  # Moderate for problem solving
doc_analyzer = 0.1  # Lower for precise documentation analysis
source_code_analyzer = 0.1  # Lower for precise code analysis
acceptance_test_generator = 0.2  # Moderate for test generation

# Example configurations for different providers:
# For OpenAI:
# provider = "openai"
# model_name = "gpt-4"
# api_key_env_var = "OPENAI_API_KEY"

# For Google Gemini (use google_genai for LangChain):
# provider = "google_genai"
# model_name = "gemini-pro"
# api_key_env_var = "GOOGLE_API_KEY"

# For Azure OpenAI:
# provider = "azure_openai"
# model_name = "gpt-4"

# General settings
project_root = "."
temp_dir = "/tmp/diversifier"
debug_mode = false
